{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(y, m):\n",
    "\n",
    "    encoded_matrix = np.zeros((m, 6))\n",
    "\n",
    "    for i in range(m):\n",
    "        encoded_matrix[i, y[i]] = 1.0\n",
    "      \n",
    "    return encoded_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation functions & their derivatives\n",
    "def sigmoid(x):\n",
    "    s = 1.0/(1.0 + np.exp(-x))\n",
    "    return s\n",
    "\n",
    "\n",
    "def relu(z):\n",
    "    r = np.maximum(0, z)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(a, y):\n",
    "    x, m = a.shape\n",
    "\n",
    "    loss = -(1.0/m) * np.sum(np.multiply(y, np.log(a)) + np.multiply(1.0 - y, np.log(1 - a)))   \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_forward(a, f, stride, pool_type):\n",
    "    (m, nh_prev, nw_prev, nc_prev) = a.shape\n",
    "    \n",
    "    nh = int(1 + (nh_prev - f)/stride)\n",
    "    nw = int(1 + (nw_prev - f)/stride)\n",
    "    nc = nc_prev\n",
    "    \n",
    "    pool_m = np.zeros((m, nh, nw, nc))\n",
    "    \n",
    "    for i in range(m):\n",
    "        for h in range(nh):\n",
    "            for w in range(nw):\n",
    "                for c in range(nc):\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    pool_slice = a[i, vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                    \n",
    "                    if pool_type == 'avg':\n",
    "                        pool_m[i, h, w, c] = np.mean(pool_slice)\n",
    "                    else:\n",
    "                        pool_m[i, h, w, c] = np.max(pool_slice)\n",
    "    return pool_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolution_forward(x, weight, b, pad, stride):\n",
    "    # get dimensions from a and w\n",
    "    (m, nh_prev, nw_prev, nc_prev) = x.shape\n",
    "    (f, f, nc_prev, nc) = weight.shape\n",
    " \n",
    "    # calc dimensions of output matrix\n",
    "    nh = int((nh_prev - f + 2 * pad) / stride) + 1\n",
    "    nw = int((nw_prev - f + 2 * pad) / stride) + 1\n",
    "    \n",
    "    z = np.zeros((m, nh, nw, nc))\n",
    "    a = np.zeros((m, nh, nw, nc))\n",
    "\n",
    "    a_pad = np.pad(x, ((0, 0), (pad, pad), (pad, pad), (0, 0)), 'constant', constant_values=0)\n",
    "    # print(a_pad[0])\n",
    "    # a_pad = np.pad(a, (pad, pad), 'constant', constant_values=0)\n",
    "\n",
    "    for i in range(m):\n",
    "        a_val = a_pad[i]\n",
    "        for h in range(nh):\n",
    "            for w in range(nw):\n",
    "                for c in range(nc):\n",
    "\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    a_slice = a_val[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "\n",
    "                    # convolution\n",
    "                    s = np.multiply(a_slice, weight[:,:,:,c]) + b[:,:,:,c]\n",
    "                    z[i, h, w, c] = np.sum(s)\n",
    "                    a[i, h, w, c] = relu(z[i, h, w, c])\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_forward(x, w1, b1, w2, b2):\n",
    "    z1 = np.dot(w1, x) + b1\n",
    "    a1 = relu(z1)\n",
    "    \n",
    "    z2 = np.dot(w2, a1) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "    return a1, a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, y, weights, biases, f_size, pad, p_stride, first_pass):\n",
    "    (w1, w2, w3, w4) = weights\n",
    "    (b1, b2, b3, b4) = biases\n",
    "    (f1, f2) = f_size\n",
    "    (pad1, pad2) = pad\n",
    "\n",
    "    (m, temp1, temp2, temp3) = x.shape\n",
    "    \n",
    "    a1 = convolution_forward(x, w1, b1, pad1, 2)\n",
    "    p1 = pool_forward(a1, f2, p_stride, pool_type='avg')\n",
    "    a2 = convolution_forward(p1, w2, b2, pad2, 2)\n",
    "    p2 = pool_forward(a2, f2, p_stride, pool_type='max')\n",
    "\n",
    "    p_shape = (p1.shape, p2.shape)\n",
    "    a3 = p2.reshape(m, -1)\n",
    "    \n",
    "    a4, a5 = full_forward(a3.T, w3, b3, w4, b4)\n",
    "    y = one_hot_encoding(y, y.shape[0]).T\n",
    "    cost = loss(a5, y)\n",
    "        \n",
    "    a = (a1, a2, a3, a4, a5)\n",
    "    p = (p1, p2)\n",
    "    \n",
    "    if first_pass is True:\n",
    "        print('Layer 1 Convolution shape {}'.format(a1.shape))\n",
    "        print('Layer 1 Pool shape {}'.format(p1.shape))\n",
    "        print('Layer 2 Convolution shape {}'.format(a2.shape))\n",
    "        print('Layer 2 Pool shape {}'.format(p2.shape))\n",
    "        print('Layer 3 Flattened shape {}'.format(a3.shape))\n",
    "        print('Layer 4 Fully connected shape {}'.format(a4.shape))\n",
    "        print('Layer 5 Fully connected shape {}'.format(a5.shape))\n",
    "    \n",
    "    return a, p_shape, p, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_mask(a):\n",
    "    mask = (a == np.max(a))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_back(a, x, y, w):\n",
    "#     a1 (108, 1020) a2 (6, 1020) w1 (108, 1296) w2 (6, 108)\n",
    "# (108, 1020) (6, 1020)\n",
    "\n",
    "    (w1, w2) = w\n",
    "    (a1, a2) = a\n",
    "    print(y.shape)\n",
    "    m = y.shape[0]\n",
    "    \n",
    "    dz2 = a2 - y\n",
    "    dz = np.dot(w2.T, dz2)\n",
    "    dw2 = (1.0/m)*np.dot(dz2, a1.T)\n",
    "    db2 = (1.0/m) * np.sum(dz2, axis=1, keepdims=True)\n",
    "    \n",
    "    # dz1 = np.dot(w2.T, dz2)\n",
    "    dz1 = np.dot(w1.T, dz)\n",
    "    dz1 = np.multiply(dz1, np.int64(a1 > 0))\n",
    "    dw1 = (1.0/m) * np.dot(dz1, x)\n",
    "    db1 = (1.0/m) * np.sum(dz1, axis=1, keepdims=True)\n",
    "\n",
    "    db = (db1, db2)\n",
    "    dw = (dw1, dw2)\n",
    "\n",
    "    print(dz1.shape)\n",
    "\n",
    "    return dw, db, dz1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_back(da, a, p_shape, f, pool_type):\n",
    "\n",
    "    m, nh_prev, nw_prev, nc_prev = a.shape\n",
    "    m, nh, nw, nc = da.shape\n",
    "        \n",
    "    a_m = np.zeros(a.shape)\n",
    "    \n",
    "    for i in range(m):\n",
    "        a_val = a[i]\n",
    "        for h in range(nh):\n",
    "            for w in range(nw):\n",
    "                for c in range(nc):\n",
    "                    vert_start = h \n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w \n",
    "                    horiz_end = horiz_start + f\n",
    "\n",
    "                    if pool_type == 'avg':\n",
    "                        avg_val = da / (f * f)\n",
    "                        temp = np.ones(f, f) * avg_val\n",
    "                        a_m[i, vert_start:vert_end, horiz_start:horiz_end, c] += temp \n",
    "                    else:\n",
    "                        a_slice = a_val[vert_start:vert_end, horiz_start:horiz_end, c]\n",
    "                        mask = gen_mask(a_slice)\n",
    "                        a_m[i, vert_start:vert_end, horiz_start:horiz_end, c] += \\\n",
    "                            (mask * da[i, h, w, c])\n",
    "    \n",
    "    return a_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_back(dz, a, weight, pad, stride):\n",
    "    (m, nh_prev, nw_prev, nc_prev) = a.shape\n",
    "    (f, f, nc_prev, nc) = weight.shape\n",
    "    \n",
    "    (m, nh, nw, nc) = dz.shape\n",
    "    \n",
    "    da = np.zeros((m, nh_prev, nw_prev, nc_prev))\n",
    "    dw = np.zeros((f, f, nc_prev, nc))\n",
    "    db = np.zeros((1, 1, 1, nc))\n",
    "    \n",
    "    a_pad = np.pad(a, ((0, 0), (pad, pad), (pad, pad), (0, 0)), 'constant', constant_values=0)\n",
    "    da_pad = np.pad(da, ((0, 0), (pad, pad), (pad, pad), (0, 0)), 'constant', constant_values=0)\n",
    "\n",
    "    for i in range(m):\n",
    "        a_val = a_pad[i]\n",
    "        da_val = da_pad[i]\n",
    "        for h in range(nh):\n",
    "            for w in range(nw):\n",
    "                for c in range(nc):\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f\n",
    "                    horiz_start = w * stride\n",
    "                    horiz_end = horiz_start + f\n",
    "                    \n",
    "                    a_slice = a_val[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "                    da_val[vert_start:vert_end, horiz_start:horiz_end, :] += weight[:,:,:,c] * \\\n",
    "                        dz[i,h,w,c]\n",
    "                    \n",
    "                    dw[:,:,:,c] += a_slice * dz[i,h,w,c]\n",
    "                    db[:,:,:,c] += dz[i,h,w,c]\n",
    "        if pad != 0:\n",
    "            da[i,:,:,:] = da_val[pad:-pad, pad:-pad, :]\n",
    "    return da, dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(x, y, a, p, w, p_shape, pad):\n",
    "    (a1, a2, a3, a4, a5) = a\n",
    "    (w1, w2, w3, w4) = w\n",
    "    (p1, p2) = p\n",
    "    (pad1, pad2) = pad\n",
    "\n",
    "    full_a = (a4, a5)\n",
    "    full_w = (w3, w4)\n",
    "    dw34, db34, dz3 = full_back(full_a, a3, y, full_w)\n",
    "\n",
    "    (p1_shape, p2_shape) = p_shape\n",
    "\n",
    "    (f, f, temp, temp) = w2.shape\n",
    "    da2 = pool_back(p2, a2, p2_shape, 5, 'max')\n",
    "    dz2 = np.where(da2 < 0, 0.0, 1.0)\n",
    "    da2, dw2, db2 = conv_back(dz2, p1, w2, pad2, 2)\n",
    "\n",
    "    (f, f, temp, temp) = w1.shape\n",
    "    da1 = pool_back(p1, a1, p1_shape, 5, 'max')\n",
    "    dz1 = np.where(da1 < 0, 0.0, 1.0)\n",
    "    da1, dw1, db1 = conv_back(dz1, x, w1, pad1, 2)\n",
    "    \n",
    "    (dw3, dw4) = dw34\n",
    "    (db3, db4) = db34\n",
    "\n",
    "    dw = (dw1, dw2, dw3, dw4)\n",
    "    db = (db1, db2, db3, db4)\n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_minibatches(batch_size, x, y, seed):\n",
    "    # np.random.seed(seed)\n",
    "    m = x.shape[0]\n",
    "    y = y.reshape(1, -1)\n",
    "    \n",
    "    # perm = list(np.random.permutation(m))\n",
    "    # shuffled_x = x[:, perm]\n",
    "    # shuffled_y = y[:, perm].reshape((1, m))\n",
    "    \n",
    "    num_batches = int(math.floor(m/batch_size))\n",
    "    \n",
    "    batches = []\n",
    "    for i in range(num_batches):\n",
    "        batch_x = x[i * batch_size:(i + 1) * batch_size, :, :, :]\n",
    "        batch_y = y[:, i * batch_size:(i + 1) * batch_size]\n",
    "        batch = (batch_x, batch_y)\n",
    "        batches.append(batch)\n",
    "    \n",
    "    # if m % batch_size != 0:\n",
    "    #     end = m - batch_size * num_batches\n",
    "    #     s = num_batches * batch_size\n",
    "    #     if s == 0:\n",
    "    #         s = 1\n",
    "    #     batch_x = x[s, :, :, :]\n",
    "    #     batch_y = y[:, num_batches * batch_size]\n",
    "    #     batch = (batch_x, batch_y)\n",
    "    #     batches.append(batch)\n",
    "\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches 12 with 85 batch size\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 Convolution shape (1020, 32, 32, 8)\nLayer 1 Pool shape (1020, 28, 28, 8)\nLayer 2 Convolution shape (1020, 13, 13, 16)\nLayer 2 Pool shape (1020, 9, 9, 16)\nLayer 3 Flattened shape (1020, 1296)\nLayer 4 Fully connected shape (108, 1020)\nLayer 5 Fully connected shape (6, 1020)\n(1020,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1296,1020) (108,1020) ",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-4d042f1dde69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_pass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mdw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mdw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdw3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdw4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mdb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-2cff13ac05f2>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(x, y, a, p, w, p_shape, pad)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mfull_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfull_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdw34\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb34\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdz3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_back\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mp1_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-225eab126499>\u001b[0m in \u001b[0;36mfull_back\u001b[0;34m(a, x, y, w)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# dz1 = np.dot(w2.T, dz2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma1\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mdw1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mdb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdz1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1296,1020) (108,1020) "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Load data\n",
    "x = np.load('ex5_train_x.npy')\n",
    "x = x/255.0\n",
    "y = np.load('ex5_train_y.npy')\n",
    "\n",
    "# set the seed\n",
    "np.random.seed(5)\n",
    "\n",
    "# Init parameters\n",
    "f1 = 4\n",
    "pad1 = 1\n",
    "stride = 2\n",
    "p_stride = 1\n",
    "f2 = 5\n",
    "pad2 = 0\n",
    "n1 = 108\n",
    "n2 = 6\n",
    "\n",
    "# w1 b1 - conv layer 1\n",
    "# w2 b2 - conv layer 2\n",
    "# w3 b3 - fully connected layer 1\n",
    "# w4 b4 - fully connected layer 2\n",
    "w1 = np.random.uniform(-1, 1, (f1, f1, 3, 8)) * 0.01\n",
    "w2 = np.random.uniform(-1, 1, (f1, f1, 8, 16)) * 0.01\n",
    "w3 = np.random.uniform(-1, 1, (n1, 1296)) * 0.01\n",
    "w4 = np.random.uniform(-1, 1, (n2, n1)) * 0.01\n",
    "\n",
    "b1 = np.zeros((1, 1, 1, 8))\n",
    "b2 = np.zeros((1, 1, 1, 16))\n",
    "b3 = np.zeros((n1, 1))\n",
    "b4 = np.zeros((n2, 1))\n",
    "\n",
    "weights = (w1, w2, w3, w4)\n",
    "biases = (b1, b2, b3, b4)\n",
    "filter_size = (f1, f2)\n",
    "\n",
    "w = (w1, w2, w3, w4)\n",
    "pad = (pad1, pad2)\n",
    "\n",
    "epochs = 1\n",
    "alpha = 0.01\n",
    "\n",
    "batch_size = 85\n",
    "num_batches = int(1020/batch_size)\n",
    "print('Number of batches {} with {} batch size\\n'.format(num_batches, batch_size))\n",
    "seed = 5\n",
    "costs = []\n",
    "mb_costs = []\n",
    "first_pass = True\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    batch_cost = 0\n",
    "    \n",
    "    seed += 1\n",
    "    batches = gen_minibatches(batch_size, x, y, seed)\n",
    "    \n",
    "    a, p_shape, p, cost = forward(x, y, weights, biases, filter_size, pad, p_stride, first_pass)\n",
    "    dw, db = backward(x, y, a, p, w, p_shape, pad)\n",
    "    (dw1, dw2, dw3, dw4) = dw\n",
    "    (db1, db2, db3, db4) = db\n",
    "    w1 = w1 - (alpha * dw1)\n",
    "    w2 = w2 - (alpha * dw2)\n",
    "    w3 = w3 - (alpha * dw3)\n",
    "    w4 = w4 - (alpha * dw4)\n",
    "\n",
    "    b1 = b1 - (alpha * db1)\n",
    "    b2 = b2 - (alpha * db2)\n",
    "    b3 = b3 - (alpha * db3)\n",
    "    b4 = b4 - (alpha * db4)\n",
    "\n",
    "    weights = (w1, w2, w3, w4)\n",
    "    biases = (b1, b2, b3, b4)\n",
    "\n",
    "    # for batch in batches:\n",
    "    #     (x, y) = batch\n",
    "    #     a, p_shape, p, cost = forward(x, y, weights, biases, filter_size, pad, p_stride, first_pass)\n",
    "    #     dw, db = backward(x, y, a, p, w, p_shape, pad)\n",
    "    #     (dw1, dw2, dw3, dw4) = dw\n",
    "    #     (db1, db2, db3, db4) = db\n",
    "    #     w1 = w1 - (alpha * dw1)\n",
    "    #     w2 = w2 - (alpha * dw2)\n",
    "    #     w3 = w3 - (alpha * dw3)\n",
    "    #     w4 = w4 - (alpha * dw4)\n",
    "    # \n",
    "    #     b1 = b1 - (alpha * db1)\n",
    "    #     b2 = b2 - (alpha * db2)\n",
    "    #     b3 = b3 - (alpha * db3)\n",
    "    #     b4 = b4 - (alpha * db4)\n",
    "    # \n",
    "    #     weights = (w1, w2, w3, w4)\n",
    "    #     biases = (b1, b2, b3, b4)\n",
    "        # mb_costs.append(cost)\n",
    "    #     batch_cost += cost\n",
    "    #     first_pass = False\n",
    "    # \n",
    "    # batch_cost = batch_cost/num_batches\n",
    "    # costs.append(batch_cost)\n",
    "\n",
    "# print('\\nFinal cost {}\\n'.format(costs[-1]))\n",
    "# plt.plot(costs)\n",
    "# plt.plot(mb_costs)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed = end_time - start_time\n",
    "\n",
    "print('Time elapsed {} mins {} secs'.format(int(elapsed/60), int(elapsed%60)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
