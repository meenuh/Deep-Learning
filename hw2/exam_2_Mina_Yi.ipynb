{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import transform\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# Load data\n",
    "x_train = np.load('exam2_train_x.npy').astype(np.float32)\n",
    "y_train = np.load('exam2_train_y.npy').astype(int)\n",
    "# x_train = x_train/255.\n",
    "\n",
    "x_test = np.load('exam2_test_x.npy').astype(np.float32)\n",
    "y_test = np.load('exam2_test_y.npy').astype(int)\n",
    "# x_test = x_test/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_augmented_data(x, y):\n",
    "    \n",
    "    new_x_imgs = []\n",
    "    new_y = []\n",
    "    for x_train, y_train in zip(x, y):\n",
    "\n",
    "        cw = transform.rotate(image=x_train, angle=15., mode='edge', resize=False, preserve_range=True)\n",
    "        ccw = transform.rotate(image=x_train, angle=-15., mode='edge', resize=False, preserve_range=True)\n",
    "\n",
    "        # new_x_imgs.append(np.flipud(x_train))\n",
    "        # new_y.append(y_train)\n",
    "        new_x_imgs.append(np.fliplr(x_train))\n",
    "        new_y.append(y_train)\n",
    "        new_x_imgs.append(cw)\n",
    "        new_y.append(y_train)\n",
    "        new_x_imgs.append(ccw)\n",
    "        new_y.append(y_train)\n",
    "\n",
    "    return new_x_imgs, new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model(features, mode, labels):\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 64, 64, 3])\n",
    "    \n",
    "    c1 = tf.layers.conv2d(inputs=input_layer, filters=32, kernel_size=[5, 5], padding='same',\n",
    "                          activation=tf.nn.relu)\n",
    "    p1 = tf.layers.max_pooling2d(inputs=c1, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    c2 = tf.layers.conv2d(inputs=p1, filters=64, kernel_size=[5, 5], padding='same',\n",
    "                          activation=tf.nn.relu)\n",
    "    p2 = tf.layers.max_pooling2d(inputs=c2, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    # c3 = tf.layers.conv2d(inputs=p2, filters=128, kernel_size=[3, 3], padding='same',\n",
    "    #                       activation=tf.nn.relu)\n",
    "    # p3 = tf.layers.max_pooling2d(inputs=c3, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    # c4 = tf.layers.conv2d(inputs=p3, filters=256, kernel_size=[3, 3], padding='valid',\n",
    "    #                       activation=tf.nn.relu)\n",
    "    # p4 = tf.layers.max_pooling2d(inputs=c4, pool_size=[2, 2], strides=2)\n",
    "    \n",
    "    # c4 = tf.layers.conv2d(inputs=p3, filters=64, kernel_size=[4, 4], padding='same',\n",
    "    #                       activation=tf.nn.relu, strides=1)\n",
    "    # p4 = tf.layers.max_pooling2d(inputs=c4, pool_size=[2, 2], strides=1)\n",
    "    \n",
    "    a5 = tf.reshape(p2, [-1, 16*16*64])\n",
    "    z5 = tf.layers.dense(a5, units=1024, activation=tf.nn.relu)\n",
    "    z5 = tf.layers.dropout(inputs=z5, rate=0.5, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "    \n",
    "    z6 = tf.layers.dense(z5, units=512, activation=tf.nn.relu)\n",
    "    z6 = tf.layers.dropout(inputs=z6, rate=0.5, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "    \n",
    "    z7 = tf.layers.dense(z6, units=6, activation=tf.nn.sigmoid)\n",
    "\n",
    "    onehot = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=6)\n",
    "\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=onehot, logits=z7)\n",
    "    \n",
    "    predictions = {'classes': tf.argmax(input=z7, axis=1),\n",
    "                   'probabilities': tf.nn.softmax(z7, name=\"softmax_tensor\")}\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(loss=loss, \n",
    "                                      global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    eval_metric_ops = {\"accuracy\": tf.metrics.accuracy(labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4080, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "newx, newy = gen_augmented_data(x_train, y_train)\n",
    "x_train = np.append(x_train, newx, axis=0).astype(np.float32)\n",
    "y_train = np.append(y_train, newy, axis=0).astype(np.int)\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "x_train = x_train/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4080, 64, 64, 3)\nINFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000023589586630>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model\\model.ckpt-200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 201 into model\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:probabilities = [[0.14494063 0.14467445 0.24894106 0.13988867 0.15806924 0.16348588]\n [0.10609204 0.10609198 0.10609198 0.10609209 0.28724504 0.28838697]\n [0.12294444 0.1218145  0.12182029 0.22428301 0.12645577 0.28268197]\n [0.10632072 0.28576633 0.28894618 0.10634518 0.106312   0.10630962]\n [0.12907574 0.12907554 0.12907971 0.3506876  0.12908766 0.13299367]\n [0.12464755 0.12464755 0.12464755 0.33882713 0.1247985  0.16243179]\n [0.12821521 0.12811154 0.13732886 0.13261028 0.1283038  0.34543028]\n [0.10688877 0.28322056 0.28988266 0.10666577 0.10668256 0.10665964]\n [0.12020255 0.11986796 0.12001205 0.12790568 0.18757285 0.3244389 ]\n [0.10597674 0.28801304 0.28806144 0.10599938 0.10597527 0.10597417]\n [0.10597369 0.28801012 0.28806    0.10600867 0.10597374 0.10597369]\n [0.17270686 0.23212083 0.21250996 0.11951911 0.11953471 0.14360851]\n [0.3503725  0.12973526 0.12978475 0.13050564 0.1297408  0.1298611 ]\n [0.13198066 0.13722292 0.15936747 0.13178053 0.30264768 0.13700074]\n [0.3444371  0.12680034 0.14398186 0.12680006 0.12680693 0.13117374]\n [0.35218653 0.12956469 0.12956221 0.12956221 0.12956218 0.12956218]\n [0.12579389 0.12895724 0.19789793 0.12586011 0.29568827 0.12580247]\n [0.10597394 0.28804442 0.28806156 0.10597336 0.10597342 0.10597333]\n [0.12945142 0.1294514  0.1297004  0.1294514  0.35188535 0.13006003]\n [0.1215394  0.12138721 0.12138721 0.12138721 0.32927263 0.18502644]\n [0.13369848 0.13369115 0.13431843 0.33000177 0.13433877 0.13395144]\n [0.10597694 0.2880503  0.28805804 0.10597086 0.10597306 0.1059708 ]\n [0.12180838 0.27857697 0.21451113 0.13636862 0.12702528 0.1217096 ]\n [0.11209776 0.2851541  0.28649145 0.10540902 0.10543833 0.1054094 ]\n [0.1048106  0.10480929 0.1048093  0.27622697 0.12555154 0.2837923 ]\n [0.35208023 0.12952334 0.12982212 0.12952325 0.12952632 0.12952475]\n [0.10726397 0.27886784 0.29157215 0.10726395 0.10776838 0.10726376]\n [0.1558315  0.15416493 0.20752317 0.15687482 0.17079684 0.15480863]\n [0.12955566 0.1295563  0.35216746 0.12958916 0.1295754  0.12955606]\n [0.10867514 0.2696919  0.2953692  0.10892523 0.10866933 0.10866927]\n [0.35217515 0.12959196 0.12955889 0.12955803 0.129558   0.129558  ]\n [0.11194596 0.11194596 0.1119467  0.30306756 0.1155249  0.2455689 ]\n [0.3521868  0.1295623  0.12956357 0.1295623  0.1295623  0.12956281]\n [0.13016663 0.280589   0.27932566 0.10329942 0.10329958 0.10331967]\n [0.11746326 0.21735568 0.31286612 0.11788931 0.11721274 0.11721282]\n [0.13567649 0.1312895  0.13138522 0.33164835 0.13150315 0.1384973 ]\n [0.12832747 0.13575938 0.34863746 0.12830919 0.13064568 0.12832081]\n [0.20425235 0.10006694 0.10006694 0.10006694 0.22367282 0.271874  ]\n [0.10601575 0.28791308 0.28810278 0.10598916 0.10598993 0.10598924]\n [0.12942518 0.12942518 0.1294385  0.12942518 0.3518141  0.13047192]\n [0.10597475 0.28804243 0.288064   0.10597286 0.10597315 0.10597283]\n [0.34868824 0.128689   0.12875362 0.12896553 0.12869056 0.13621297]\n [0.12954454 0.12954454 0.12961325 0.12960336 0.35213852 0.12955575]\n [0.12250436 0.17749745 0.33274162 0.12241611 0.12242072 0.12241969]\n [0.29017767 0.10675894 0.10675894 0.10675894 0.10676133 0.2827842 ]\n [0.11722497 0.11797421 0.2890121  0.11714838 0.24039565 0.11824471]\n [0.10595671 0.10595671 0.10595671 0.28777972 0.10633037 0.28801966]\n [0.12936097 0.12934268 0.12935686 0.1293427  0.35158956 0.13100713]\n [0.11188369 0.11134236 0.11134241 0.26077333 0.11149269 0.29316553]\n [0.1117056  0.2861621  0.28623375 0.10529952 0.10529952 0.10529952]\n [0.12954202 0.12954202 0.1295425  0.35213116 0.12960964 0.1296326 ]\n [0.10597589 0.28805658 0.28805673 0.10597035 0.10597035 0.10597017]\n [0.10598263 0.10597725 0.10597766 0.10629152 0.2879108  0.28786016]\n [0.10623139 0.10620773 0.10620778 0.10630566 0.286548   0.28849947]\n [0.10953911 0.10937873 0.10949765 0.10940361 0.29651797 0.26566288]\n [0.12202207 0.12202207 0.12202207 0.12270495 0.179544   0.33168483]\n [0.12544034 0.12542897 0.12542953 0.34080204 0.12546277 0.15743625]\n [0.17947733 0.12120979 0.12120997 0.12121144 0.32941705 0.12747437]\n [0.12969106 0.12950324 0.12950327 0.1295796  0.1296967  0.35202616]\n [0.35218656 0.1295622  0.1295622  0.12956221 0.1295622  0.12956467]\n [0.1270802  0.12707461 0.14627533 0.12707451 0.34541255 0.12708272]\n [0.33699185 0.12397248 0.12397248 0.12397268 0.15418428 0.13690627]\n [0.12896152 0.15479185 0.340389   0.12527463 0.1253056  0.12527733]\n [0.11140078 0.11144715 0.27728045 0.11507446 0.27323568 0.11156143]\n [0.11151797 0.11151189 0.11153126 0.12869865 0.2415643  0.2951759 ]\n [0.11220599 0.24604167 0.30499974 0.11225446 0.1122811  0.11221711]\n [0.11402435 0.2857229  0.28451326 0.10528813 0.10522687 0.10522448]\n [0.35082945 0.12907316 0.12907417 0.12907363 0.1328694  0.12908024]\n [0.11178605 0.11176571 0.1118183  0.30180776 0.12373291 0.23908928]\n [0.10597137 0.28805825 0.28805828 0.10597073 0.10597073 0.10597073]\n [0.12587751 0.12586828 0.12588991 0.12586974 0.15435417 0.3421404 ]\n [0.10599469 0.28797334 0.28808755 0.10598149 0.10598149 0.10598149]\n [0.10597093 0.28805697 0.28805837 0.10597114 0.10597172 0.10597092]\n [0.14307237 0.12631786 0.12634514 0.1263205  0.13462506 0.3433191 ]\n [0.28821686 0.28637233 0.1063332  0.10701516 0.10603125 0.10603124]\n [0.10339168 0.10339168 0.10339194 0.12787765 0.28095046 0.28099656]\n [0.10574064 0.28714725 0.28743044 0.10574037 0.10820136 0.10574003]\n [0.12160946 0.12161148 0.12205718 0.17707679 0.3287836  0.12886141]\n [0.2197017  0.11314704 0.11314731 0.3075181  0.11314715 0.1333387 ]\n [0.10601915 0.28773367 0.28818795 0.10601848 0.10602232 0.10601844]\n [0.10597405 0.28803933 0.28806546 0.1059738  0.105974   0.10597338]\n [0.1860771  0.12685451 0.12685451 0.12685628 0.30409238 0.1292652 ]\n [0.12686723 0.12686743 0.12689589 0.12704144 0.34481072 0.14751726]\n [0.10735176 0.10733754 0.10739025 0.1073548  0.29172078 0.27884492]\n [0.12873821 0.13477479 0.34983242 0.1290725  0.12873688 0.12884519]\n [0.12587455 0.15408367 0.34207758 0.12597515 0.12612937 0.1258596 ]\n [0.3520975  0.12953009 0.12959975 0.12971231 0.12953009 0.12953019]\n [0.3521415  0.12954569 0.12954569 0.12954608 0.12954941 0.12967156]\n [0.10722753 0.28764963 0.2876544  0.10582283 0.10582283 0.10582283]\n [0.13917483 0.14107436 0.27043802 0.1390645  0.16369335 0.14655499]\n [0.12881954 0.12869303 0.12879227 0.13471256 0.12953243 0.34945017]\n [0.12207998 0.1220728  0.12208393 0.12215417 0.3272171  0.18439206]\n [0.14253676 0.13591918 0.3043422  0.13599561 0.14516176 0.13604453]\n [0.1209335  0.11926819 0.2812158  0.2400276  0.11969078 0.11886411]\n [0.10732028 0.10730241 0.10730241 0.10730334 0.2791821  0.29158947]\n [0.13210854 0.13212109 0.13410318 0.13494453 0.33411607 0.13260661]\n [0.34999615 0.12932514 0.12935272 0.13002099 0.129307   0.13199799]\n [0.10651439 0.28863677 0.28568444 0.10648368 0.10634192 0.10633886]\n [0.11888052 0.11888178 0.11889111 0.11892144 0.32309225 0.20133297]\n [0.33040464 0.1215491  0.12172367 0.1215491  0.18322438 0.12154917]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.2147787, step = 201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.20858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:probabilities = [[0.35217994 0.12955993 0.12958032 0.12956019 0.12955981 0.1295598 ]\n [0.12951793 0.12951499 0.12951718 0.12959543 0.12980162 0.35205284]\n [0.12117113 0.32812423 0.17424525 0.13431175 0.12107841 0.12106914]\n [0.1283145  0.1283375  0.12833284 0.34803152 0.12853467 0.13844903]\n [0.1267918  0.12684007 0.15032308 0.12675819 0.34242985 0.12685704]\n [0.12689538 0.3445306  0.14795719 0.12692244 0.12684715 0.12684712]\n [0.12883662 0.3486043  0.13674799 0.12864542 0.12858656 0.12857918]\n [0.1295603  0.1295603  0.1295603  0.12957142 0.12956694 0.35218075]\n [0.13264999 0.12908426 0.12979159 0.35044372 0.12901539 0.12901501]\n [0.35160166 0.12934704 0.12934707 0.12934707 0.12934704 0.13101012]\n [0.12474608 0.12970491 0.33841798 0.12499139 0.155998   0.12614171]\n [0.12866156 0.34970957 0.13260858 0.13170095 0.12865968 0.12865968]\n [0.12949318 0.12949318 0.1295117  0.13000353 0.35199887 0.12949955]\n [0.11055158 0.2815644  0.27498093 0.11241568 0.11024468 0.11024276]\n [0.11972655 0.11973366 0.19735378 0.32227466 0.11978439 0.121127  ]\n [0.16586229 0.12380939 0.12398954 0.12464086 0.1253772  0.3363207 ]\n [0.13260049 0.13136426 0.13139907 0.1313643  0.14364126 0.3296306 ]\n [0.12512404 0.12512347 0.12512349 0.15920433 0.12556957 0.3398551 ]\n [0.12332422 0.12652431 0.24729548 0.14583464 0.12417567 0.23284571]\n [0.12125324 0.22166646 0.29227164 0.12230608 0.12125146 0.12125116]\n [0.1290672  0.12906726 0.1290718  0.35084078 0.13286842 0.12908448]\n [0.12804368 0.13166514 0.12838617 0.34784448 0.13592635 0.12813419]\n [0.27850762 0.10245906 0.10245906 0.16461104 0.24950409 0.10245906]\n [0.12578385 0.1300758  0.34186354 0.15071158 0.12578516 0.12578006]\n [0.1208468  0.12084607 0.12084607 0.18815278 0.1208635  0.32844484]\n [0.12957963 0.12970766 0.35153306 0.12958124 0.13002245 0.12957592]\n [0.12801807 0.12838794 0.13326858 0.13468428 0.12883821 0.3468029 ]\n [0.12766054 0.12766011 0.14240304 0.12767798 0.34693775 0.12766054]\n [0.1294242  0.12942426 0.13042964 0.12942554 0.35180196 0.12949443]\n [0.13161626 0.12918738 0.12921283 0.12918745 0.35113704 0.12965907]\n [0.12795417 0.1285053  0.12797695 0.34717217 0.13173515 0.13665624]\n [0.10206567 0.19831532 0.27628958 0.21919549 0.10206822 0.10206566]\n [0.12955871 0.12955871 0.12955871 0.35217708 0.1295881  0.12955871]\n [0.12828924 0.1271764  0.12718444 0.14287299 0.13162076 0.34285617]\n [0.13174681 0.1385924  0.3275896  0.1389591  0.13173157 0.13138054]\n [0.12903193 0.12953298 0.13568516 0.34712082 0.12959744 0.12903172]\n [0.11702064 0.21357769 0.12250369 0.31232464 0.11754484 0.11702852]\n [0.13032994 0.12944943 0.12944943 0.12945503 0.12945147 0.3518647 ]\n [0.11722422 0.11722378 0.11722516 0.31834537 0.11755072 0.21243079]\n [0.12012643 0.12012643 0.12012643 0.19204268 0.12105907 0.32651886]\n [0.10600556 0.2881473  0.28783283 0.10600473 0.10600473 0.10600473]\n [0.12770027 0.12770225 0.12885334 0.34422842 0.14380454 0.12771128]\n [0.3521805  0.12956214 0.12956887 0.12956218 0.12956215 0.12956421]\n [0.12928605 0.12928623 0.12928733 0.13111131 0.12960081 0.35142827]\n [0.352158   0.12959604 0.12955256 0.12958287 0.12955782 0.12955278]\n [0.10867114 0.10866854 0.10867509 0.21169606 0.2862114  0.17607774]\n [0.10973887 0.10980616 0.10975168 0.29352304 0.11133738 0.2658429 ]\n [0.12952372 0.12952518 0.12962456 0.35208157 0.12972067 0.12952434]\n [0.13502051 0.15201697 0.1399182  0.24053459 0.13730207 0.19520764]\n [0.1290304  0.12903054 0.12905437 0.3502359  0.1321194  0.13052937]\n [0.3521789  0.12955938 0.12955938 0.12958361 0.12955938 0.12955938]\n [0.12938379 0.13073087 0.12941028 0.3516891  0.12939015 0.1293959 ]\n [0.12518816 0.15974922 0.33804575 0.12564528 0.12619963 0.12517197]\n [0.3417391  0.12572022 0.12572022 0.12572052 0.12572643 0.15537348]\n [0.12079415 0.32669324 0.19134572 0.1205508  0.12031008 0.12030604]\n [0.10641912 0.2852072  0.28903085 0.10651208 0.10641536 0.10641537]\n [0.1160263  0.18112937 0.3146703  0.15612139 0.11602632 0.1160263 ]\n [0.13023485 0.35001534 0.13299602 0.12891798 0.12891793 0.12891793]\n [0.13180119 0.13327788 0.13542335 0.33005366 0.13764219 0.13180181]\n [0.13211624 0.12730584 0.14277466 0.15876274 0.12756932 0.31147128]\n [0.1295623  0.12955828 0.12955946 0.1295806  0.129564   0.3521753 ]\n [0.12557946 0.12559924 0.34135768 0.15630476 0.12557946 0.12557946]\n [0.12945025 0.13022062 0.351877   0.12955154 0.1294503  0.12945025]\n [0.12714201 0.14150861 0.34559488 0.13146695 0.12714551 0.12714201]\n [0.3493748  0.12948665 0.12948696 0.13168637 0.13044336 0.12952179]\n [0.1416056  0.2854537  0.14112067 0.14963982 0.14109015 0.14109007]\n [0.10893201 0.10893237 0.10893212 0.268414   0.29585662 0.1089329 ]\n [0.12902868 0.12902865 0.13286568 0.12903261 0.35071117 0.12933326]\n [0.35218745 0.12956253 0.12956253 0.12956253 0.12956253 0.12956253]\n [0.12952195 0.12952386 0.12952211 0.3520771  0.12983304 0.129522  ]\n [0.12707366 0.27765408 0.28278592 0.10416215 0.10416213 0.10416213]\n [0.12787539 0.12787402 0.1279599  0.12788522 0.3475603  0.14084522]\n [0.12926166 0.12926193 0.13077259 0.12947021 0.35134614 0.12988743]\n [0.12982655 0.1292158  0.12930045 0.12939736 0.13202861 0.35023123]\n [0.3516163  0.12935448 0.12935835 0.12935448 0.12935849 0.13095786]\n [0.3521874  0.12956251 0.12956253 0.12956259 0.12956251 0.12956251]\n [0.11911658 0.11911944 0.19931895 0.11969751 0.32362774 0.11911981]\n [0.12937638 0.12937593 0.12941132 0.12938678 0.35167944 0.13077006]\n [0.12948793 0.12948793 0.12948795 0.12948793 0.13006364 0.35198465]\n [0.12944736 0.12944736 0.13033624 0.12944736 0.35187438 0.12944736]\n [0.35213655 0.12954544 0.12967905 0.12954551 0.1295476  0.12954588]\n [0.35215777 0.12955344 0.12955405 0.1295535  0.12955451 0.12962674]\n [0.11806027 0.11808173 0.25379512 0.27175453 0.12009721 0.11821116]\n [0.12950264 0.12950264 0.12950264 0.35202464 0.12996456 0.12950283]\n [0.11376468 0.11277634 0.11277779 0.30563107 0.24227326 0.11277687]\n [0.15513614 0.15334013 0.18827866 0.17028359 0.15284264 0.18011887]\n [0.12795119 0.1392655  0.12804745 0.34736037 0.12876691 0.1286085 ]\n [0.12617908 0.12617913 0.15197632 0.3429842  0.1265022  0.12617913]\n [0.1172953  0.1193705  0.2473037  0.11920666 0.27999663 0.11682724]\n [0.10613228 0.28716904 0.28830048 0.10613302 0.1061333  0.10613193]\n [0.1283171  0.12822117 0.13377644 0.13294435 0.34851968 0.1282213 ]\n [0.10634264 0.2883676  0.2850363  0.10737335 0.10653999 0.10634016]\n [0.14097531 0.14090359 0.25056753 0.17865956 0.14805764 0.1408364 ]\n [0.3521836  0.12956178 0.1295655  0.12956445 0.12956287 0.12956181]\n [0.12208454 0.12183663 0.19179086 0.12183708 0.32061383 0.12183712]\n [0.12955756 0.12956053 0.35217345 0.12956548 0.12958537 0.12955756]\n [0.12935144 0.12935379 0.12995182 0.35156262 0.13042891 0.12935139]\n [0.1100544  0.29787382 0.2595735  0.11238949 0.1100544  0.1100544 ]\n [0.12742513 0.12742524 0.12742563 0.34636956 0.14337507 0.12797938]\n [0.1295418  0.12954178 0.12968278 0.12957639 0.35211542 0.12954181]] (82.743 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.1723671, step = 301 (82.748 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.26549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:probabilities = [[0.35218745 0.12956253 0.12956253 0.12956253 0.12956253 0.12956253]\n [0.12950571 0.12950571 0.12950572 0.12950571 0.35203302 0.12994418]\n [0.12956035 0.12956038 0.12956034 0.3521812  0.12957351 0.12956426]\n [0.12955911 0.12955911 0.12955911 0.12955911 0.12958533 0.3521782 ]\n [0.34906843 0.12841517 0.12841517 0.12841517 0.12841517 0.13727093]\n [0.35218745 0.12956253 0.12956253 0.12956253 0.12956253 0.12956253]\n [0.3520594  0.12960428 0.1296135  0.12965748 0.12953098 0.12953426]\n [0.11850499 0.24631901 0.13117826 0.26698318 0.11850777 0.11850681]\n [0.35072863 0.12902594 0.12902594 0.13316773 0.12902594 0.12902594]\n [0.14962347 0.13178319 0.13178311 0.13649875 0.13178311 0.31852832]\n [0.10903954 0.10903954 0.10903954 0.26767468 0.10912698 0.29607964]\n [0.35218745 0.12956253 0.12956253 0.12956253 0.12956253 0.12956253]\n [0.1263689  0.12637946 0.13469605 0.34249428 0.14369237 0.12636898]\n [0.12943704 0.12943694 0.1294372  0.12943788 0.13041261 0.35183832]\n [0.12956893 0.35217816 0.12957548 0.12955919 0.12955917 0.12955919]\n [0.12955466 0.12955666 0.35216364 0.12961617 0.12955444 0.12955444]\n [0.35218745 0.12956253 0.12956253 0.12956254 0.12956253 0.12956253]\n [0.12952241 0.12952241 0.12983197 0.12952241 0.3520784  0.12952241]\n [0.1295625  0.35218734 0.12956253 0.12956269 0.1295625  0.1295625 ]\n [0.12504235 0.12504236 0.12504248 0.16082966 0.3389841  0.1250589 ]\n [0.1302715  0.33326876 0.13984376 0.13607307 0.13027151 0.1302715 ]\n [0.12956251 0.12956251 0.12956251 0.12956251 0.12956251 0.35218742]\n [0.1295784  0.35212263 0.12967768 0.12954107 0.12954009 0.12954007]\n [0.12780456 0.12780456 0.12781675 0.12780851 0.3432105  0.14555517]\n [0.3521834  0.12956175 0.12956177 0.12956175 0.12956217 0.1295691 ]\n [0.12955156 0.12955156 0.12955156 0.12955156 0.35215762 0.12963614]\n [0.12956251 0.12956251 0.12956251 0.12956251 0.12956251 0.35218742]\n [0.12871319 0.12871319 0.34987533 0.12871349 0.13527164 0.12871319]\n [0.35216218 0.12955436 0.12955476 0.1295707  0.12958692 0.12957111]\n [0.12100529 0.12100529 0.12100529 0.32891706 0.13404782 0.17401928]\n [0.3521551  0.1295671  0.12957187 0.1295671  0.12956917 0.12956972]\n [0.35218492 0.12956166 0.12956189 0.12956166 0.12956466 0.12956515]\n [0.14751382 0.1562037  0.24756823 0.15191656 0.14928399 0.14751376]\n [0.12955752 0.12955238 0.12963615 0.1295524  0.35214218 0.12955937]\n [0.1293317  0.12933168 0.13040908 0.12933199 0.35124037 0.13035518]\n [0.12969908 0.12943524 0.3510748  0.12942731 0.13093637 0.1294272 ]\n [0.12901951 0.35061005 0.13329633 0.12903526 0.12901948 0.12901932]\n [0.12955062 0.12955232 0.12955643 0.35215384 0.12963608 0.12955076]\n [0.10627025 0.2888723  0.2860467  0.10627025 0.10627025 0.10627025]\n [0.35218745 0.12956253 0.12956253 0.12956253 0.12956253 0.12956253]\n [0.12954079 0.35212272 0.12971961 0.12953892 0.12953892 0.12953892]\n [0.12900892 0.12900664 0.13060933 0.12957674 0.350429   0.13136934]\n [0.12956235 0.12956235 0.12956363 0.12956235 0.35218698 0.12956235]\n [0.11616848 0.11616785 0.21969268 0.11616729 0.31563643 0.11616729]\n [0.12953354 0.12953338 0.12953442 0.1295334  0.35210586 0.12975945]\n [0.12790772 0.1279072  0.34745    0.12790751 0.14092039 0.12790728]\n [0.1283022  0.1283022  0.1283052  0.34874508 0.13796034 0.12838504]\n [0.1319691  0.32864588 0.14512746 0.1313228  0.13180667 0.13112806]\n [0.12956187 0.12956187 0.12956187 0.12956187 0.35218567 0.1295669 ]\n [0.10955205 0.10955205 0.10955205 0.2708093  0.29088658 0.10964799]\n [0.12957872 0.35208204 0.12962508 0.12957136 0.12957136 0.12957136]\n [0.35218745 0.12956253 0.12956253 0.12956254 0.12956253 0.12956253]\n [0.15433024 0.17633332 0.15875944 0.15589562 0.20032889 0.15435237]\n [0.12956107 0.12956107 0.3521824  0.12956107 0.1295733  0.12956107]\n [0.12153924 0.12153149 0.32919005 0.12154069 0.18466553 0.12153298]\n [0.12957849 0.12959419 0.35206303 0.12960391 0.12958188 0.12957852]\n [0.12955244 0.12953953 0.12953958 0.12953955 0.1297054  0.35212347]\n [0.12959324 0.35198498 0.12993328 0.12949646 0.12949526 0.12949686]\n [0.35174507 0.12940347 0.12940347 0.13005777 0.12940371 0.12998655]\n [0.12865308 0.34969905 0.13570507 0.12864763 0.12864755 0.12864755]\n [0.12953241 0.12977432 0.35209587 0.12953258 0.12953244 0.12953241]\n [0.12946285 0.12946291 0.12947229 0.3519136  0.13022365 0.12946482]\n [0.12938565 0.1294081  0.12996624 0.12948684 0.35164952 0.13010356]\n [0.12955467 0.12955467 0.12955497 0.1296145  0.3521661  0.12955506]\n [0.28817993 0.28775793 0.10601555 0.10601555 0.10601555 0.10601555]\n [0.1292243  0.12922394 0.12922402 0.12922394 0.1318386  0.35126522]\n [0.12955238 0.12955238 0.12955238 0.12955238 0.1296305  0.3521599 ]\n [0.1288863  0.12888615 0.12888615 0.13412735 0.12888624 0.35032782]\n [0.129563   0.352186   0.12956248 0.12956364 0.12956244 0.12956244]\n [0.12345842 0.12350653 0.33541924 0.1235007  0.17065656 0.1234585 ]\n [0.12831758 0.13712399 0.3475932  0.12841083 0.13023779 0.12831669]\n [0.13046052 0.13043483 0.34737986 0.1308516  0.13043907 0.13043419]\n [0.3507793  0.12927009 0.1292701  0.12940551 0.1292831  0.13199195]\n [0.12956245 0.35218725 0.12956299 0.12956245 0.12956245 0.12956245]\n [0.12956251 0.12956251 0.12956251 0.12956251 0.3521874  0.12956254]\n [0.12909392 0.15248689 0.13972716 0.32052103 0.12908557 0.12908553]\n [0.10632089 0.10631999 0.10631999 0.10631999 0.28577825 0.28894094]\n [0.12955981 0.12955967 0.12958123 0.3521793  0.1295596  0.12956041]\n [0.12955981 0.12955981 0.12955981 0.12955981 0.12958068 0.35218006]\n [0.12956159 0.12956159 0.12956879 0.12956159 0.3521849  0.12956159]\n [0.12968321 0.12984794 0.351993   0.1294917  0.12949173 0.1294925 ]\n [0.35218742 0.12956251 0.12956251 0.12956251 0.12956251 0.1295626 ]\n [0.12956251 0.12956251 0.12956251 0.12956251 0.3521874  0.12956256]\n [0.12956169 0.1295648  0.12956169 0.3521852  0.1295618  0.12956479]\n [0.12796056 0.34515184 0.14306235 0.12794176 0.12794176 0.12794176]\n [0.12984547 0.35168993 0.12966576 0.12961216 0.12958318 0.12960355]\n [0.11068708 0.11055102 0.11053365 0.297476   0.26018095 0.11057125]\n [0.12955883 0.12956247 0.12955925 0.35217735 0.1295594  0.12958269]\n [0.12983045 0.12983836 0.34924728 0.13030878 0.13094479 0.12983032]\n [0.1295289  0.12952666 0.12952663 0.12953462 0.12979731 0.3520859 ]\n [0.12824135 0.15104482 0.33598974 0.12824135 0.12824135 0.12824135]\n [0.12953296 0.12953296 0.12953296 0.12953296 0.12976271 0.35210538]\n [0.11099931 0.3012375  0.25476825 0.11100004 0.11099748 0.11099748]\n [0.13079529 0.13065214 0.1308595  0.13274589 0.13171741 0.34322977]\n [0.10896761 0.10896761 0.10896761 0.10896762 0.29618135 0.2679482 ]\n [0.34033504 0.12521464 0.12521464 0.12521477 0.12521464 0.15880628]\n [0.12958157 0.12958157 0.12958157 0.1295825  0.1296602  0.35201266]\n [0.12604292 0.12604403 0.12604322 0.34261155 0.15321366 0.1260446 ]\n [0.35218742 0.12956251 0.12956251 0.1295626  0.12956251 0.12956251]\n [0.1295139  0.12992404 0.35177872 0.12951365 0.12975624 0.1295135 ]] (81.161 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.123713, step = 401 (81.160 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 1.2026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:probabilities = [[0.35207015 0.12958065 0.12957068 0.12963714 0.12957068 0.12957068]\n [0.35216892 0.12956293 0.12956369 0.12956242 0.12956372 0.12957828]\n [0.3292507  0.12163033 0.12141008 0.12140924 0.12141164 0.18488812]\n [0.12955435 0.35216266 0.12962289 0.1295534  0.1295534  0.1295534 ]\n [0.12938382 0.12935016 0.12935019 0.12935106 0.13110594 0.35145876]\n [0.12907995 0.129081   0.13311374 0.35049644 0.12908831 0.12914057]\n [0.12956248 0.12956248 0.12956254 0.12956248 0.35218734 0.12956262]\n [0.10722356 0.10722356 0.2874711  0.10736109 0.28349727 0.10722356]\n [0.12956251 0.12956251 0.35218742 0.12956251 0.12956251 0.12956251]\n [0.12956215 0.35218632 0.12956515 0.12956212 0.12956212 0.12956212]\n [0.12955928 0.12955928 0.12955928 0.12955928 0.3521786  0.1295843 ]\n [0.12931709 0.13122274 0.3514754  0.12931739 0.1293504  0.12931708]\n [0.1295597  0.1295597  0.12955974 0.12958159 0.12955971 0.35217956]\n [0.34998658 0.12877116 0.13498048 0.12875393 0.12875393 0.12875393]\n [0.1197897  0.19521971 0.11979009 0.325621   0.1197897  0.1197897 ]\n [0.1295624  0.1295624  0.1295624  0.1295624  0.3521871  0.12956335]\n [0.10929063 0.10929082 0.2763812  0.2864561  0.10929063 0.10929067]\n [0.12956479 0.12956122 0.12956147 0.12956122 0.35218373 0.12956747]\n [0.11056792 0.11056823 0.11058183 0.2573169  0.30028927 0.11067586]\n [0.12954631 0.1295466  0.12959573 0.35213643 0.12955205 0.1296229 ]\n [0.12961012 0.3521617  0.12955335 0.12955347 0.12955335 0.12956798]\n [0.1296042  0.35214534 0.12960736 0.1295477  0.1295477  0.1295477 ]\n [0.12939955 0.12939955 0.13005547 0.35156497 0.12958282 0.12999758]\n [0.12956198 0.35218477 0.12956865 0.12956154 0.12956154 0.12956154]\n [0.12941083 0.12940958 0.12940958 0.12940958 0.13058878 0.3517716 ]\n [0.35218745 0.12956253 0.12956253 0.12956253 0.12956253 0.12956253]\n [0.1295625  0.1295625  0.1295625  0.1295625  0.12956262 0.35218737]\n [0.1286787  0.13063055 0.12874201 0.3430987  0.1398193  0.12903073]\n [0.12949216 0.12949221 0.12949185 0.12949185 0.13003851 0.35199335]\n [0.12904546 0.12904494 0.12904494 0.1290464  0.13305849 0.35075974]\n [0.10887837 0.10887837 0.10887837 0.10887837 0.29555357 0.2689329 ]\n [0.1230332  0.1230332  0.1230332  0.1230332  0.17356277 0.33430445]\n [0.12828915 0.12826777 0.13824041 0.1282678  0.34866711 0.12826778]\n [0.12955227 0.35215783 0.12963319 0.12955247 0.12955207 0.12955207]\n [0.3505525  0.12926376 0.1305706  0.12926397 0.13108182 0.12926735]\n [0.35218745 0.12956253 0.12956253 0.12956253 0.12956253 0.12956253]\n [0.12926508 0.12926485 0.12926555 0.3505037  0.13238789 0.12931298]\n [0.12559047 0.12559035 0.12559581 0.14790495 0.33832133 0.13699718]\n [0.12956007 0.12955911 0.12955916 0.12955911 0.3521782  0.12958433]\n [0.12952818 0.12952831 0.12953255 0.3520025  0.12988025 0.12952818]\n [0.12956326 0.12956344 0.35218272 0.12956326 0.12956406 0.12956326]\n [0.1295625  0.3521873  0.12956254 0.12956272 0.12956248 0.12956248]\n [0.12825434 0.1283237  0.12825702 0.34861434 0.13827159 0.12827893]\n [0.12599915 0.15366614 0.34235924 0.12599301 0.12599121 0.12599121]\n [0.28806403 0.10597311 0.28804356 0.10597311 0.10597311 0.10597311]\n [0.1295606  0.35218185 0.12957557 0.12956084 0.12956057 0.12956057]\n [0.12860174 0.1286014  0.12860142 0.1286015  0.34955487 0.1360391 ]\n [0.35218745 0.12956253 0.12956253 0.12956253 0.12956254 0.12956253]\n [0.12953915 0.12953913 0.12953913 0.12953956 0.1297195  0.3521235 ]\n [0.12921698 0.12921697 0.12921937 0.35123798 0.12942886 0.1316798 ]\n [0.12955035 0.1295504  0.12958251 0.35214233 0.12958191 0.12959252]\n [0.12955515 0.12955515 0.12955515 0.1295553  0.1296119  0.35216737]\n [0.35218745 0.12956253 0.12956253 0.12956253 0.12956253 0.12956253]\n [0.12955998 0.12955998 0.12957938 0.12956008 0.3521805  0.12956001]\n [0.35218745 0.12956253 0.12956253 0.12956253 0.12956253 0.12956253]\n [0.12956126 0.12956126 0.1295711  0.12956128 0.35218364 0.12956142]\n [0.34832513 0.12814176 0.12814188 0.12814178 0.12814176 0.1391077 ]\n [0.12954482 0.12953748 0.12972459 0.35211393 0.12953934 0.12953994]\n [0.12955739 0.12955739 0.12955754 0.12959568 0.35217345 0.1295585 ]\n [0.12957418 0.35218126 0.12956332 0.12956044 0.12956041 0.12956041]\n [0.12938711 0.12938161 0.12938161 0.12938161 0.1307729  0.35169512]\n [0.12952152 0.1298199  0.3520744  0.12952238 0.1295403  0.1295215 ]\n [0.35218745 0.12956253 0.12956253 0.12956253 0.12956253 0.12956253]\n [0.12508315 0.1252637  0.15948398 0.3399959  0.12508923 0.12508395]\n [0.13358448 0.12894152 0.12894349 0.12894183 0.12915999 0.3504287 ]\n [0.35217935 0.12958227 0.12955956 0.12955956 0.12955956 0.12955974]\n [0.12897532 0.35020843 0.1338056  0.12906028 0.12897518 0.12897518]\n [0.11923803 0.31955293 0.2035106  0.11919604 0.1193201  0.11918231]\n [0.35218745 0.12956253 0.12956253 0.12956253 0.12956253 0.12956253]\n [0.12955816 0.1295581  0.1295581  0.1295581  0.1295922  0.35217527]\n [0.12948567 0.12948565 0.12948565 0.35197824 0.13007912 0.1294857 ]\n [0.19111134 0.12139743 0.12120986 0.1239518  0.121211   0.32111862]\n [0.11126889 0.11127139 0.30186212 0.11127444 0.25305432 0.11126881]\n [0.12917282 0.12917283 0.13218243 0.12917307 0.35112596 0.12917283]\n [0.1293315  0.1293315  0.1293315  0.1293315  0.13111457 0.3515594 ]\n [0.12931027 0.12930728 0.1293074  0.12930728 0.13171831 0.35104948]\n [0.10958786 0.28955498 0.27209365 0.10958786 0.10958786 0.10958786]\n [0.2804618  0.14290881 0.14292556 0.14616913 0.14296253 0.14457217]\n [0.3521812  0.12956023 0.12956037 0.12956023 0.12957688 0.12956126]\n [0.12943807 0.35167697 0.13075176 0.12937771 0.12937775 0.12937771]\n [0.12956247 0.12956247 0.12956247 0.12956281 0.12956247 0.35218728]\n [0.35218745 0.12956253 0.12956253 0.12956253 0.12956253 0.12956253]\n [0.12343434 0.12466529 0.17130794 0.3337237  0.12343436 0.12343434]\n [0.12457202 0.12458146 0.12462747 0.16337316 0.33824372 0.12460217]\n [0.10989139 0.10988709 0.10989751 0.10988709 0.27878848 0.28164837]\n [0.12983951 0.3520413  0.12952486 0.1295331  0.1295233  0.12953793]\n [0.12657775 0.12657775 0.14959252 0.12660633 0.34406787 0.12657776]\n [0.1295673  0.35197413 0.12978362 0.1295667  0.12949553 0.12961277]\n [0.1290998  0.12900247 0.12900247 0.12900269 0.13327223 0.3506204 ]\n [0.12923607 0.12923457 0.1315104  0.12923463 0.3512858  0.12949856]\n [0.12956253 0.12956251 0.12956251 0.12956251 0.12956253 0.3521874 ]\n [0.13023373 0.13233514 0.12975883 0.13857168 0.12976047 0.33934012]\n [0.12956251 0.12956251 0.12956251 0.12956251 0.12956257 0.3521874 ]\n [0.14157128 0.14196846 0.1416211  0.29167104 0.14159688 0.14157128]\n [0.129524   0.129524   0.129524   0.129524   0.35208258 0.12982143]\n [0.12956253 0.35218742 0.12956254 0.12956253 0.12956253 0.12956253]\n [0.12849118 0.1288278  0.12887236 0.34788078 0.13257587 0.133352  ]\n [0.12956251 0.12956251 0.12956251 0.3521874  0.12956251 0.12956254]\n [0.13996403 0.12801477 0.12801477 0.34797683 0.12801477 0.12801488]\n [0.10648914 0.28926343 0.28478056 0.10648896 0.10648895 0.10648895]] (81.013 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.0846535, step = 501 (81.010 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 600 into model\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 1.090927.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x23589586358>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.set_random_seed(5)\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "clf = tf.estimator.Estimator(model_fn=conv_model, model_dir='model')\n",
    "\n",
    "log_hook = tf.train.LoggingTensorHook(tensors={\"probabilities\": \"softmax_tensor\"}, every_n_iter=100)\n",
    "\n",
    "train_input = tf.estimator.inputs.numpy_input_fn(x={'x': x_train}, \n",
    "                                                 y=y_train, batch_size=100, \n",
    "                                                 num_epochs=None, shuffle=True)\n",
    "clf.train(input_fn=train_input, steps=400, hooks=[log_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-04-15-08:20:44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model\\model.ckpt-600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2018-04-15-08:20:45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 600: accuracy = 0.92777777, global_step = 600, loss = 1.1324644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.92777777, 'loss': 1.1324644, 'global_step': 600}\n"
     ]
    }
   ],
   "source": [
    "predict_input = tf.estimator.inputs.numpy_input_fn(\n",
    "    {'x': x_test}, y=y_test, num_epochs=1, shuffle=False)\n",
    "results = clf.evaluate(input_fn=predict_input)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
